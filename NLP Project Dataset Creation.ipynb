{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>account</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_pp</th>\n",
       "      <th>tweet_raw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margaritis Schinas</td>\n",
       "      <td>@MargSchinas</td>\n",
       "      <td>1189630376186204161</td>\n",
       "      <td>une ipe d'arte regards a accompagn &lt;mention&gt; p...</td>\n",
       "      <td>b\"Une équipe d'ARTE Regards a accompagné @Junc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Margaritis Schinas</td>\n",
       "      <td>@MargSchinas</td>\n",
       "      <td>1189510536452546565</td>\n",
       "      <td>c r , v le , newton ... un nouvel n europ gr n...</td>\n",
       "      <td>b'César, Vésale, Newton... Un nouvel élan euro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Margaritis Schinas</td>\n",
       "      <td>@MargSchinas</td>\n",
       "      <td>1188425686643544064</td>\n",
       "      <td>today at the exceptional li and magritte &lt;ment...</td>\n",
       "      <td>b'Today at the exceptional “Dali and Magritte”...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Margaritis Schinas</td>\n",
       "      <td>@MargSchinas</td>\n",
       "      <td>1187041401554526208</td>\n",
       "      <td>back from strasbourg , this afternoon with &lt;me...</td>\n",
       "      <td>b'Back from Strasbourg, this afternoon with ⁦@...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Margaritis Schinas</td>\n",
       "      <td>@MargSchinas</td>\n",
       "      <td>1185911684948512768</td>\n",
       "      <td>happy to deliver today the keynote speech to t...</td>\n",
       "      <td>b'Happy to deliver today the keynote speech to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               person       account             tweet_id  \\\n",
       "0  Margaritis Schinas  @MargSchinas  1189630376186204161   \n",
       "1  Margaritis Schinas  @MargSchinas  1189510536452546565   \n",
       "2  Margaritis Schinas  @MargSchinas  1188425686643544064   \n",
       "3  Margaritis Schinas  @MargSchinas  1187041401554526208   \n",
       "4  Margaritis Schinas  @MargSchinas  1185911684948512768   \n",
       "\n",
       "                                            tweet_pp  \\\n",
       "0  une ipe d'arte regards a accompagn <mention> p...   \n",
       "1  c r , v le , newton ... un nouvel n europ gr n...   \n",
       "2  today at the exceptional li and magritte <ment...   \n",
       "3  back from strasbourg , this afternoon with <me...   \n",
       "4  happy to deliver today the keynote speech to t...   \n",
       "\n",
       "                                           tweet_raw  label  \n",
       "0  b\"Une équipe d'ARTE Regards a accompagné @Junc...      1  \n",
       "1  b'César, Vésale, Newton... Un nouvel élan euro...      1  \n",
       "2  b'Today at the exceptional “Dali and Magritte”...      1  \n",
       "3  b'Back from Strasbourg, this afternoon with ⁦@...      1  \n",
       "4  b'Happy to deliver today the keynote speech to...      1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Talha/data_publish/data_all.csv',lineterminator='\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making dataset for different experiments\n",
    "1. Person Split\n",
    "2. Gender Split\n",
    "3. Location Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Person Split \n",
    "\n",
    "I first split the data by adding all tweets from each real – parody account pair to a single split, either train, development or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the file as CSV \n",
    "# CSV(Comma-separated-value), It is easier to read compared to tsv(Tab-separated-value) and can be opened on Excel.\n",
    "\n",
    "# Making dataset for testing on persons experiment\n",
    "dfpersontrain = pd.read_csv('C:/Users/Talha/data_publish/persons/train.txt', sep=\",\",header = None)\n",
    "dfpersontrain.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfpersontrain=dfpersontrain.merge(df, on='tweet_id')\n",
    "dfpersontrain=dfpersontrain.drop(columns='label_x',axis=1)\n",
    "dfpersontrain=dfpersontrain.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfpersontraincsv = dfpersontrain\n",
    "dfpersontraincsv.to_csv(\"C:/Users/Talha/data_publish/persons/persontrain.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for testing on persons experiment\n",
    "\n",
    "dfpersontest = pd.read_csv('C:/Users/Talha/data_publish/persons/test.txt', sep=\",\",header = None)\n",
    "dfpersontest.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfpersontest=dfpersontest.merge(df, on='tweet_id')\n",
    "dfpersontest=dfpersontest.drop(columns='label_x',axis=1)\n",
    "dfpersontest=dfpersontest.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfpersontestcsv = dfpersontest\n",
    "dfpersontestcsv.to_csv(\"C:/Users/Talha/data_publish/persons/persontest.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for development on persons experiment\n",
    "\n",
    "dfpersondev = pd.read_csv('C:/Users/Talha/data_publish/persons/dev.txt', sep=\",\",header = None)\n",
    "dfpersondev.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfpersondev=dfpersondev.merge(df, on='tweet_id')\n",
    "dfpersondev=dfpersondev.drop(columns='label_x',axis=1)\n",
    "dfpersondev=dfpersondev.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfpersondevcsv = dfpersondev\n",
    "dfpersondevcsv.to_csv(\"C:/Users/Talha/data_publish/persons/persondev.csv\", sep=',',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gender Split\n",
    "\n",
    "I also split the data by the gender into training, development and test, obtaining two versions of the data: \n",
    "(i) one with female accounts in train/dev and male in test\n",
    "(ii) male accounts in train/dev and female in test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 female accounts in train/dev and male in test\n",
    "\n",
    "# CSV(Comma-separated-value), It is easier to read compared to tsv(Tab-separated-value) and can be opened on Excel.\n",
    "\n",
    "# Making dataset for training female data on gender experiment\n",
    "dfgenderfemaletrain = pd.read_csv('C:/Users/Talha/data_publish/gender/test_on_male/female_train.txt', sep=\",\",header = None)\n",
    "dfgenderfemaletrain.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfgenderfemaletrain=dfgenderfemaletrain.merge(df, on='tweet_id')\n",
    "dfgenderfemaletrain=dfgenderfemaletrain.drop(columns='label_x',axis=1)\n",
    "dfgenderfemaletrain=dfgenderfemaletrain.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfgenderfemaletraincsv = dfgenderfemaletrain\n",
    "dfgenderfemaletraincsv.to_csv(\"C:/Users/Talha/data_publish/gender/test_on_male/femaletrain.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for development female data on gender experiment\n",
    "\n",
    "dfgenderfemaledev = pd.read_csv('C:/Users/Talha/data_publish/gender/test_on_male/female_dev.txt', sep=\",\",header = None)\n",
    "dfgenderfemaledev.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfgenderfemaledev=dfgenderfemaledev.merge(df, on='tweet_id')\n",
    "dfgenderfemaledev=dfgenderfemaledev.drop(columns='label_x',axis=1)\n",
    "dfgenderfemaledev=dfgenderfemaledev.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfgenderfemaledevcsv = dfgenderfemaledev\n",
    "dfgenderfemaledevcsv.to_csv(\"C:/Users/Talha/data_publish/gender/test_on_male/femaledev.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for testing male data on gender experiment\n",
    "\n",
    "dfgendermaletest = pd.read_csv('C:/Users/Talha/data_publish/gender/test_on_male/male_test.txt', sep=\",\",header = None)\n",
    "dfgendermaletest.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfgendermaletest=dfgendermaletest.merge(df, on='tweet_id')\n",
    "dfgendermaletest=dfgendermaletest.drop(columns='label_x',axis=1)\n",
    "dfgendermaletest=dfgendermaletest.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfgendermaletestcsv = dfgendermaletest\n",
    "dfgendermaletestcsv.to_csv(\"C:/Users/Talha/data_publish/gender/test_on_male/maletest.csv\", sep=',',index=False)\n",
    "\n",
    "# 2 male accounts in train/dev and female in test \n",
    "\n",
    "# CSV(Comma-separated-value), It is easier to read compared to tsv(Tab-separated-value) and can be opened on Excel.\n",
    "\n",
    "# Making dataset for training male data on gender experiment\n",
    "dfgendermaletrain = pd.read_csv('C:/Users/Talha/data_publish/gender/test_on_female/male_train.txt', sep=\",\",header = None)\n",
    "dfgendermaletrain.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfgendermaletrain=dfgendermaletrain.merge(df, on='tweet_id')\n",
    "dfgendermaletrain=dfgendermaletrain.drop(columns='label_x',axis=1)\n",
    "dfgendermaletrain=dfgendermaletrain.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfgendermaletraincsv = dfgendermaletrain\n",
    "dfgendermaletraincsv.to_csv(\"C:/Users/Talha/data_publish/gender/test_on_female/maletrain.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for development male data on gender experiment\n",
    "\n",
    "dfgendermaledev = pd.read_csv('C:/Users/Talha/data_publish/gender/test_on_female/male_dev.txt', sep=\",\",header = None)\n",
    "dfgendermaledev.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfgendermaledev=dfgendermaledev.merge(df, on='tweet_id')\n",
    "dfgendermaledev=dfgendermaledev.drop(columns='label_x',axis=1)\n",
    "dfgendermaledev=dfgendermaledev.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfgendermaledevcsv = dfgendermaledev\n",
    "dfgendermaledevcsv.to_csv(\"C:/Users/Talha/data_publish/gender/test_on_female/maledev.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for testing female data on gender experiment\n",
    "\n",
    "dfgenderfemaletest = pd.read_csv('C:/Users/Talha/data_publish/gender/test_on_female/female_test.txt', sep=\",\",header = None)\n",
    "dfgenderfemaletest.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dfgenderfemaletest=dfgenderfemaletest.merge(df, on='tweet_id')\n",
    "dfgenderfemaletest=dfgenderfemaletest.drop(columns='label_x',axis=1)\n",
    "dfgenderfemaletest=dfgenderfemaletest.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dfgenderfemaletestcsv = dfgenderfemaletest\n",
    "dfgenderfemaletestcsv.to_csv(\"C:/Users/Talha/data_publish/gender/test_on_female/femaletest.csv\", sep=',',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Location Split\n",
    "\n",
    "I split the data based on the location of the politicians. I group the accounts in three groups of locations: US, UK and\n",
    "the rest of the world (RoW). I obtain three different splits, where each group makes up the test set and the other two groups make up the train and development set.\n",
    "\n",
    "(i) one with us,uk location accounts in train/dev and ROW in test\n",
    "(ii) second with ROW,UK location accounts in train/dev and US in test\n",
    "(iii) third ROW,US location accounts in train/dev and UK in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 US,UK location accounts in train/dev and ROW in test\n",
    "\n",
    "# CSV(Comma-separated-value), It is easier to read compared to tsv(Tab-separated-value) and can be opened on Excel.\n",
    "\n",
    "# Making dataset for training US,UK location data on location experiment\n",
    "dflocationUKUStrain = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_intl/us_uk_train.txt', \n",
    "                                  sep=\",\",header = None)\n",
    "dflocationUKUStrain.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUKUStrain=dflocationUKUStrain.merge(df, on='tweet_id')\n",
    "dflocationUKUStrain=dflocationUKUStrain.drop(columns='label_x',axis=1)\n",
    "dflocationUKUStrain=dflocationUKUStrain.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUKUStraincsv = dflocationUKUStrain\n",
    "dflocationUKUStraincsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_intl/usuktrain.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for development US,UK location data on location experiment\n",
    "\n",
    "dflocationUKUSdev = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_intl/us_uk_dev.txt', sep=\",\",header = None)\n",
    "dflocationUKUSdev.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUKUSdev=dflocationUKUSdev.merge(df, on='tweet_id')\n",
    "dflocationUKUSdev=dflocationUKUSdev.drop(columns='label_x',axis=1)\n",
    "dflocationUKUSdev=dflocationUKUSdev.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUKUSdevcsv = dflocationUKUSdev\n",
    "dflocationUKUSdevcsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_intl/usukdev.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for testing ROW data on location experiment\n",
    "\n",
    "dflocationintltest = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_intl/intl_test.txt', sep=\",\",header = None)\n",
    "dflocationintltest.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationintltest=dflocationintltest.merge(df, on='tweet_id')\n",
    "dflocationintltest=dflocationintltest.drop(columns='label_x',axis=1)\n",
    "dflocationintltest=dflocationintltest.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationintltestcsv = dflocationintltest\n",
    "dflocationintltestcsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_intl/intltest.csv\", sep=',',index=False)\n",
    "\n",
    "# 2 US,ROW location accounts in train/dev and UK in test\n",
    "\n",
    "# CSV(Comma-separated-value), It is easier to read compared to tsv(Tab-separated-value) and can be opened on Excel.\n",
    "\n",
    "# Making dataset for training US,UK location data on location experiment\n",
    "dflocationUSIntltrain = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_uk/us_intl_train.txt', \n",
    "                                    sep=\",\",header = None)\n",
    "dflocationUSIntltrain.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUSIntltrain=dflocationUSIntltrain.merge(df, on='tweet_id')\n",
    "dflocationUSIntltrain=dflocationUSIntltrain.drop(columns='label_x',axis=1)\n",
    "dflocationUSIntltrain=dflocationUSIntltrain.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUSIntltraincsv = dflocationUSIntltrain\n",
    "dflocationUSIntltraincsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_uk/usintltrain.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for development US,ROW location data on location experiment\n",
    "\n",
    "dflocationUSIntldev = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_uk/us_intl_dev.txt', sep=\",\",header = None)\n",
    "dflocationUSIntldev.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUSIntldev=dflocationUSIntldev.merge(df, on='tweet_id')\n",
    "dflocationUSIntldev=dflocationUSIntldev.drop(columns='label_x',axis=1)\n",
    "dflocationUSIntldev=dflocationUSIntldev.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUSIntldevcsv = dflocationUSIntldev\n",
    "dflocationUSIntldevcsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_uk/usintldev.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for testing UK data on location experiment\n",
    "\n",
    "dflocationUKtest = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_uk/uk_test.txt', sep=\",\",header = None)\n",
    "dflocationUKtest.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUKtest=dflocationUKtest.merge(df, on='tweet_id')\n",
    "dflocationUKtest=dflocationUKtest.drop(columns='label_x',axis=1)\n",
    "dflocationUKtest=dflocationUKtest.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUKtestcsv = dflocationUKtest\n",
    "dflocationUKtestcsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_uk/uktest.csv\", sep=',',index=False)\n",
    "\n",
    "# 3 UK,ROW location accounts in train/dev and US in test\n",
    "\n",
    "# CSV(Comma-separated-value), It is easier to read compared to tsv(Tab-separated-value) and can be opened on Excel.\n",
    "\n",
    "# Making dataset for training UK, ROW location data on location experiment\n",
    "dflocationUKIntltrain = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_us/uk_intl_train.txt', \n",
    "                                    sep=\",\",header = None)\n",
    "dflocationUKIntltrain.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUKIntltrain=dflocationUKIntltrain.merge(df, on='tweet_id')\n",
    "dflocationUKIntltrain=dflocationUKIntltrain.drop(columns='label_x',axis=1)\n",
    "dflocationUKIntltrain=dflocationUKIntltrain.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUKIntltraincsv = dflocationUKIntltrain\n",
    "dflocationUKIntltraincsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_us/ukintltrain.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for development UK,ROW location data on location experiment\n",
    "\n",
    "dflocationUKIntldev = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_us/uk_intl_dev.txt', sep=\",\",header = None)\n",
    "dflocationUKIntldev.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUKIntldev=dflocationUKIntldev.merge(df, on='tweet_id')\n",
    "dflocationUKIntldev=dflocationUKIntldev.drop(columns='label_x',axis=1)\n",
    "dflocationUKIntldev=dflocationUKIntldev.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUKIntldevcsv = dflocationUKIntldev\n",
    "dflocationUKIntldevcsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_us/ukintldev.csv\", sep=',',index=False)\n",
    "\n",
    "# Making dataset for testing US data on location experiment\n",
    "\n",
    "dflocationUStest = pd.read_csv('C:/Users/Talha/data_publish/location/test_on_us/us_test.txt', sep=\",\",header = None)\n",
    "dflocationUStest.columns = [\"tweet_id\",\"label\"]\n",
    "\n",
    "dflocationUStest=dflocationUStest.merge(df, on='tweet_id')\n",
    "dflocationUStest=dflocationUStest.drop(columns='label_x',axis=1)\n",
    "dflocationUStest=dflocationUStest.rename(columns={'label_y': 'label'})\n",
    "\n",
    "dflocationUStestcsv = dflocationUStest\n",
    "dflocationUStestcsv.to_csv(\"C:/Users/Talha/data_publish/location/test_on_us/ustest.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
